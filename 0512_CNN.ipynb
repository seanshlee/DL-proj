{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanshlee/DL-proj/blob/main/0512_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuKwAe02WMc6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #구글 드라이브에 연결하는 코드"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import pickle\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #GPU 사용 설정\n",
        "\n",
        "train_dataset_path = '/content/drive/MyDrive/emo_train_dataset_0508.pkl' \n",
        "test_dataset_path = '/content/drive/MyDrive/emo_test_dataset_0508.pkl'"
      ],
      "metadata": {
        "id": "DjfWrOrn2mPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset, test_dataset pkl 파일 불러오기 \n",
        "with open(train_dataset_path, 'rb') as f:\n",
        "  train_dataset = pickle.load(f)\n",
        "\n",
        "with open(test_dataset_path, 'rb') as f:\n",
        "  test_dataset = pickle.load(f)"
      ],
      "metadata": {
        "id": "ytAn16GnWyT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨값에 해당하는 숫자를 label_set에 저장.\n",
        "label_set = {'angry': 0,\n",
        " 'disgusted': 1,\n",
        " 'fearful': 2,\n",
        " 'happy': 3,\n",
        " 'neutral': 4,\n",
        " 'sad': 5,\n",
        " 'surprised': 6,\n",
        "}"
      ],
      "metadata": {
        "id": "PFqkU1_mfteH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨값 숫자로 변환해서 train_data에 저장\n",
        "#img 차원값이 맨 앞으로 오도록 reshape (torch 포맷에 맞게)\n",
        "#이미지값 255로 나눠서 정규화 \n",
        "\n",
        "train_data = []\n",
        "for img, label in train_dataset:\n",
        "  train_data.append((img.reshape(1,48,48)/255., label_set[label]))"
      ],
      "metadata": {
        "id": "niA3ilJ43eeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨값 숫자로 변환해서 test_data에 저장\n",
        "#img 차원값이 맨 앞으로 오도록 reshape (torch 포맷에 맞게)\n",
        "#이미지값 255로 나눠서 정규화 \n",
        "\n",
        "test_data = []\n",
        "for img, label in test_dataset:\n",
        "  test_data.append((img.reshape(1,48,48)/255., label_set[label]))"
      ],
      "metadata": {
        "id": "mkBtH02W31P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#자료형을 텐서로 변경해서 train, test에 저장. -> Data load 할 준비 완료\n",
        "train = [(torch.tensor(im, dtype=torch.float32),torch.tensor(label, dtype=torch.long)) for im,label in train_data]\n",
        "test = [(torch.tensor(im,dtype=torch.float32),torch.tensor(label, dtype=torch.long)) for im,label in test_data]"
      ],
      "metadata": {
        "id": "VgvmtsjKu3rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper parameter 설정 \n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 120\n",
        "LEARNING_RATE = 1e-3"
      ],
      "metadata": {
        "id": "c-vFF8ac7n4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader \n",
        "train_loader = DataLoader(train, batch_size = BATCH_SIZE, shuffle=True) #drop_last = True"
      ],
      "metadata": {
        "id": "lw9ngPflUlD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_loader.__iter__())[0].shape #Size 확인 코드 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3LoohYAS0E9",
        "outputId": "3b887566-4074-4b1d-c3b3-bb394ab73513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 48, 48])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test, batch_size = BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "E8ZMCL4Pt7or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_final(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act1 = nn.LeakyReLU()\n",
        "        self.drop1 = nn.Dropout(0.2)\n",
        " \n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act2 = nn.LeakyReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act3 = nn.LeakyReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        " \n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "        #48*48 이 MaxPool2d 2번을 거치면서 12*12가 됨\n",
        "        #크기가 12*12인 텐서 64개 출력\n",
        "        self.fc4 = nn.Linear(12*12*64, 512)\n",
        "        self.act4 = nn.LeakyReLU()\n",
        "        self.drop4 = nn.Dropout(0.2)\n",
        " \n",
        "        self.fc5 = nn.Linear(512, 7)\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.flat(x)\n",
        "        x = self.act4(self.fc4(x))\n",
        "        x = self.drop4(x)\n",
        "\n",
        "        x = self.fc5(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "DVfP1xLTN5-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN_final()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "KwOzhRkoWyTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adadelta(model.parameters(), lr=LEARNING_RATE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "8DrII23CW2X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_set2 = {0: 'angry',\n",
        " 1: 'disgusted',\n",
        " 2: 'fearful',\n",
        " 3: 'happy',\n",
        " 4: 'neutral',\n",
        " 5: 'sad',\n",
        " 6: 'surprised'\n",
        "}"
      ],
      "metadata": {
        "id": "zZWs65EDSqV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import clear_output\n",
        "total = 0 \n",
        "correct = 0 \n",
        "##############\n",
        "total_acc = []\n",
        "best_acc = 0\n",
        "best_epoch = 0\n",
        "patience = 30\n",
        "counter = 0 \n",
        "\n",
        "#학습진행\n",
        "losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss=[]\n",
        "  for img, label in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(img.to(device))\n",
        "    loss = criterion(pred, label.long().to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  losses.append(np.array(train_loss).mean())\n",
        "  \n",
        "#평가\n",
        "  test_loss= []\n",
        "  test_sources = []\n",
        "  with torch.no_grad():\n",
        "    for img, label in test_loader:\n",
        "      pred = model(img.to(device))\n",
        "    \n",
        "      loss = criterion(pred, label.long().to(device))\n",
        "\n",
        "      test_loss.append(loss.item())\n",
        "      test_sources.append((img[pred.cpu().argmax(axis=1)!=label.cpu()],\n",
        "      label[pred.cpu().argmax(axis=1)!=label.cpu()],pred.cpu().argmax(axis=1)[pred.cpu().argmax(axis=1)!=label.cpu()])) \n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  # 인식 잘 안된 부분의 시각화를 위해서 img, label, pred를 모아서 정리\n",
        "  imgs = [x[0] for x in test_sources]\n",
        "  imgs = torch.cat(imgs, axis=0)\n",
        "\n",
        "  labels = [x[1] for x in test_sources]\n",
        "  labels = torch.cat(labels, axis=0)\n",
        "\n",
        "  preds = [x[2] for x in test_sources]\n",
        "  preds = torch.cat(preds, axis=0)\n",
        "\n",
        "  # 정확도 계산을 위한 코드. 다양하게 다른 방법도 가능함\n",
        "  wrongs = [len(x[0]) for x in test_sources]\n",
        "  acc = round(100-(sum(wrongs)/100),2)\n",
        "\n",
        "  # 정확도 추이를 보기 위하여 각 에폭에서의 정확도 정보 수집\n",
        "  total_acc.append(acc)\n",
        "\n",
        "  # 학습 진행 상황 출력\n",
        "  print(\"{}번째 train_loss : {} test_loss : {} Accuracy : {}%\".format(epoch, round(np.array(train_loss).mean(),2),round(np.array(test_loss).mean(),2),\n",
        "                                                                   acc))\n",
        "  if img.shape[0]<1:continue # 혹시 더이상 오분류 내용이 없으면 지나가도록 세팅\n",
        "\n",
        "  #가장 높은 정확도를 달성한 epoch 정보 저장\n",
        "  if acc > best_acc:\n",
        "    best_acc = acc\n",
        "    best_epoch = epoch\n",
        "    counter = 0 \n",
        "    torch.save(model.state_dict(), 'best_model.pt')\n",
        "    \n",
        "  else :\n",
        "    counter += 1\n",
        "    if counter >= patience:\n",
        "      print(\"Early stopping...\")\n",
        "      break\n",
        "\n",
        "  print(\"Best accuracy {}% achieved at epoch {}\".format(best_acc, best_epoch))\n",
        "\n",
        "  # 정확도 그래프 그리기\n",
        "  plt.plot(total_acc)\n",
        "  plt.show()\n",
        "\n",
        "  # 오분류 내용이 어떤건지 알기 위해 오분류 내용 4개 뽑아서 label과 pred 글자 넣어서 표시\n",
        "  for i in range(4):\n",
        "    plt.subplot(1,4,i+1)    \n",
        "    plt.imshow(imgs[i][0], cmap='gray')    \n",
        "\n",
        "    plt.title(\"{} vs {}\".format(label_set2[int(labels[i].item())],label_set2[int(preds[i].item())]))\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "20AQan1_W266"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  print(\"Best accuracy {}% achieved at epoch {}\".format(best_acc, best_epoch))\n"
      ],
      "metadata": {
        "id": "IPYKFBuyVG2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec58188-10ff-48f7-8e51-3cabe0b837b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy 68.04% achieved at epoch 28\n"
          ]
        }
      ]
    }
  ]
}
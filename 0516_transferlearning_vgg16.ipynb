{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanshlee/DL-proj/blob/main/0516_transferlearning_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb7z4cN9IPtn",
        "outputId": "ee1ff821-8e82-450f-910a-ddbbd952ac79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #구글 드라이브에 연결하는 코드"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import pickle\n",
        "\n",
        "#GPU를 사용하도록 설정\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #GPU 사용 설정\n",
        "\n",
        "train_dataset_path = '/content/drive/MyDrive/emo_train_dataset_0508.pkl' \n",
        "test_dataset_path = '/content/drive/MyDrive/emo_test_dataset_0508.pkl'"
      ],
      "metadata": {
        "id": "4TeVmWyAISc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset, test_dataset pkl 파일 불러오기 \n",
        "with open(train_dataset_path, 'rb') as f:\n",
        "  train_dataset = pickle.load(f)\n",
        "\n",
        "with open(test_dataset_path, 'rb') as f:\n",
        "  test_dataset = pickle.load(f)"
      ],
      "metadata": {
        "id": "xaEc5YAJJl9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨값에 해당하는 숫자를 label_set에 저장.\n",
        "label_set = {'angry': 0,\n",
        " 'disgusted': 1,\n",
        " 'fearful': 2,\n",
        " 'happy': 3,\n",
        " 'neutral': 4,\n",
        " 'sad': 5,\n",
        " 'surprised': 6,\n",
        "}"
      ],
      "metadata": {
        "id": "zj19x8TOJnhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨값 숫자로 변환해서 train_data에 저장\n",
        "#img 차원값이 맨 앞으로 오도록 reshape (torch 포맷에 맞게)\n",
        "\n",
        "train_data = []\n",
        "for img, label in train_dataset:\n",
        "  train_data.append((img.reshape(1,48,48), label_set[label]))"
      ],
      "metadata": {
        "id": "B5Xu11xAJpK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨값 숫자로 변환해서 test_data에 저장\n",
        "#img 차원값이 맨 앞으로 오도록 reshape (torch 포맷에 맞게)\n",
        "\n",
        "test_data = []\n",
        "for img, label in test_dataset:\n",
        "  test_data.append((img.reshape(1,48,48), label_set[label]))"
      ],
      "metadata": {
        "id": "L0pQscNNJpEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#자료형을 텐서로 변경해서 train, test에 저장. -> Data load 할 준비 완료\n",
        "train = [(torch.tensor(im, dtype=torch.float32),torch.tensor(label, dtype=torch.long)) for im,label in train_data]\n",
        "test = [(torch.tensor(im,dtype=torch.float32),torch.tensor(label, dtype=torch.long)) for im,label in test_data]"
      ],
      "metadata": {
        "id": "SevcvV2BJrbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxRJErcsJvHa",
        "outputId": "30f7a5f3-0c09-4dac-b2ab-90971219eaa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 48, 48])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper parameter 설정 \n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 1e-4"
      ],
      "metadata": {
        "id": "P23T1O2vJwfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader \n",
        "train_loader = DataLoader(train, batch_size = BATCH_SIZE, shuffle=True) #drop_last = True\n",
        "test_loader = DataLoader(test, batch_size = BATCH_SIZE, shuffle=True) #drop_last = True"
      ],
      "metadata": {
        "id": "_LByXyzHJzVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "id": "WuBcspmERwKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "#vgg16 모델을 가져와서 사용\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "#첫번째 레이어의 채널 수를 3에서 1로 수정\n",
        "#마지막 레이어의 출력 클래스 수를 7로 수정\n",
        "\n",
        "model.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "model.classifier[6] = nn.Linear(4096, 7)"
      ],
      "metadata": {
        "id": "GQ1sbXHcR2N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전이학습"
      ],
      "metadata": {
        "id": "aBtl6IHZJ09w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "aGhiVShqflzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "FLfLJ-z3Ngm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import clear_output\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "##############\n",
        "total_acc = []\n",
        "best_acc = 0\n",
        "best_epoch = 0\n",
        "patience = 25\n",
        "counter = 0\n",
        "\n",
        "#학습진행\n",
        "losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss=[]\n",
        "  for img, label in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(img.to(device))\n",
        "    loss = criterion(pred, label.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  losses.append(np.array(train_loss).mean())\n",
        "\n",
        "#평가\n",
        "  test_loss= []\n",
        "  test_sources = []\n",
        "  with torch.no_grad():\n",
        "    for img, label in test_loader:\n",
        "      pred = model(img.to(device))\n",
        "      loss = criterion(pred, label.to(device))\n",
        "      test_loss.append(loss.item())\n",
        "      test_sources.append((img[pred.cpu().argmax(axis=1)!=label.cpu()],\n",
        "      label[pred.cpu().argmax(axis=1)!=label.cpu()],pred.cpu().argmax(axis=1)[pred.cpu().argmax(axis=1)!=label.cpu()]))\n",
        "  clear_output()\n",
        "\n",
        "  # 인식 잘 안된 부분의 시각화를 위해서 img, label, pred를 모아서 정리\n",
        "  imgs = [x[0] for x in test_sources]\n",
        "  imgs = torch.cat(imgs, axis=0)\n",
        "  labels = [x[1] for x in test_sources]\n",
        "  labels = torch.cat(labels, axis=0)\n",
        "  preds = [x[2] for x in test_sources]\n",
        "  preds = torch.cat(preds, axis=0)\n",
        "\n",
        "  # 정확도 계산을 위한 코드. 다양하게 다른 방법도 가능함\n",
        "  wrongs = [len(x[0]) for x in test_sources]\n",
        "  acc = round(100-(sum(wrongs)/100),2)\n",
        "\n",
        "  # 정확도 추이를 보기 위하여 각 에폭에서의 정확도 정보 수집\n",
        "  total_acc.append(acc)\n",
        "  \n",
        "  # 학습 진행 상황 출력\n",
        "  print(\"{}번째 train_loss : {} test_loss : {} Accuracy : {}%\".format(epoch, round(np.array(train_loss).mean(),2),round(np.array(test_loss).mean(),2),\n",
        "                                                                   acc))\n",
        "  if img.shape[0]<1:continue # 혹시 더이상 오분류 내용이 없으면 지나가도록 세팅\n",
        "  \n",
        "  #가장 높은 정확도를 달성한 epoch 정보 저장\n",
        "  if acc > best_acc:\n",
        "    best_acc = acc\n",
        "    best_epoch = epoch\n",
        "    counter = 0\n",
        "    torch.save(model.state_dict(), 'best_model_vgg16.pt') \n",
        "  else :\n",
        "    counter += 1\n",
        "    if counter >= patience:\n",
        "      print(\"Early stopping...\")\n",
        "      break\n",
        "  print(\"Best accuracy {}% achieved at epoch {}\".format(best_acc, best_epoch))\n",
        "  \n",
        "  # 정확도 그래프 그리기\n",
        "  plt.plot(total_acc)\n",
        "  plt.show()\n",
        "  plt.title(\"label vs pred\")\n",
        "  label_list = ['angry','disgusted','fearful','happy','neutral','sad','surprised']\n",
        "  \n",
        "  # 오분류 내용이 어떤건지 알기 위해 오분류 내용 4개 뽑아서 label과 pred 글자 넣어서 표시\n",
        "  for i in range(4):\n",
        "    plt.subplot(1,4,i+1)\n",
        "    label = label_list[labels[i].item()]\n",
        "    pred = label_list[preds[i].item()]    \n",
        "    plt.imshow(imgs[i][0], cmap='gray')    \n",
        "    plt.title(\"{} vs {}\".format(label,pred))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "3EIUZYLFNl6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  print(\"Best accuracy {}% achieved at epoch {}\".format(best_acc, best_epoch))"
      ],
      "metadata": {
        "id": "OGvv_aghRIMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}